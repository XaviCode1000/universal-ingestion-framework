# ğŸ›¸ Universal Ingestion Framework (UIF)

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Architecture: Multi-Layer](https://img.shields.io/badge/architecture-multi--layer-orange.svg)]()
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)]()
[![Tests: 75 passing](https://img.shields.io/badge/tests-75%20passing-brightgreen.svg)]()

[ğŸ‡ºğŸ‡¸ Leer en InglÃ©s](README.md)

UIF es un motor de ingesta de conocimiento de alta fidelidad diseÃ±ado para transformar infraestructuras web legacy y activos documentales binarios en bases de datos Markdown optimizadas para LLMs y sistemas RAG (Retrieval-Augmented Generation).

---

## ğŸ›‘ CAPACIDADES DE Ã‰LITE

- **Ingesta Multimodal HÃ­brida**: ConversiÃ³n de alta fidelidad para `PDF`, `DOCX`, `XLSX` y `PPTX` vÃ­a **MarkItDown**, y extracciÃ³n semÃ¡ntica superior para HTML vÃ­a **Trafilatura**.
- **Limpieza de "Grado Industrial"**: Pipeline de pre-poda con **Selectolax**, sanitizaciÃ³n con **nh3** y normalizaciÃ³n Unicode con **ftfy** para eliminar el 100% del ruido y el *mojibake*.
- **NavegaciÃ³n Inteligente (Scope Control)**: Estrategias `SMART`, `STRICT` y `BROAD` para controlar con precisiÃ³n quirÃºrgica el alcance del rastreo (evitando salir de sub-sitios o documentaciÃ³n especÃ­fica).
- **Contexto RAG Enriquecido**: InyecciÃ³n automÃ¡tica de **YAML Frontmatter** (URL, autor, fecha, tÃ­tulo) en cada archivo para facilitar la indexaciÃ³n en bases de datos vectoriales.
- **Resiliencia Industrial**: GestiÃ³n de estado mediante **SQLite en modo WAL**, permitiendo concurrencia real y recuperaciÃ³n automÃ¡tica tras fallos.
- **UX Conversacional**: Asistente interactivo (Wizard) para configuraciÃ³n guiada de alcance, procesos y tipos de contenido.

---

## ğŸ—ï¸ ARQUITECTURA TÃ‰CNICA (Pipeline v3.0.0 - Modular Enterprise)

El motor opera en cuatro capas de refinamiento:

1. **Capa de NavegaciÃ³n (Scrapling + Scope Logic)**: OrquestaciÃ³n asÃ­ncrona con evasiÃ³n de bloqueos y filtrado de alcance inteligente basado en la profundidad de la URL semilla.
2. **Capa de PurificaciÃ³n (Selectolax + Density Analysis)**: EliminaciÃ³n masiva de ruido mediante selectores estÃ¡ticos y un **Algoritmo de Densidad de Enlaces** que detecta y elimina menÃºs/sidebars incluso en sitios no semÃ¡nticos.
3. **Capa de ConversiÃ³n HÃ­brida**: SelecciÃ³n dinÃ¡mica del mejor motor con **Estrategia de TÃ­tulo en Cascada** (Waterfall) para garantizar metadatos precisos, usando **Trafilatura** y **MarkItDown**.
4. **Capa de Refinamiento (ftfy + YAML)**: NormalizaciÃ³n final del texto (mojibake fix) y enriquecimiento con metadatos estructurados para mÃ¡xima compatibilidad con sistemas RAG.

---

## ğŸ§ª TESTING

UIF incluye una suite de tests completa con **75+ tests** cubriendo escenarios unitarios, de integraciÃ³n y end-to-end:

```bash
# Ejecutar todos los tests
uv run pytest tests/ -v

# Solo tests rÃ¡pidos (sin browser e2e)
uv run pytest tests/ -v -k "not browser"

# Con reporte de cobertura
uv run pytest tests/ -v --cov=uif_scraper --cov-report=html

# Solo tests end-to-end (requiere internet)
uv run pytest tests/test_e2e.py tests/test_e2e_browser.py -v
```

### Cobertura de Tests

| CategorÃ­a | Tests | DescripciÃ³n |
|-----------|-------|-------------|
| Unit Tests | 51 | NavegaciÃ³n, extractores, DB, utils |
| E2E (HTTP) | 4 | Peticiones HTTP reales a webscraper.io |
| E2E (Browser) | 3 | AutomatizaciÃ³n completa con Chromium |
| Integration | 17 | OrquestaciÃ³n del engine, shutdown, reportes |

---

## ğŸš€ INSTALACIÃ“N Y USO

Este proyecto utiliza `uv` para una gestiÃ³n de dependencias ultrarrÃ¡pida y determinista.

### Pre-requisitos
```bash
# Instalar uv si no lo tienes
curl -LsSf https://astral.sh/uv/install.sh | sh

# Instalar dependencias y lock file
uv sync
```

### ConfiguraciÃ³n del Navegador (Opcional - para tests E2E con browser)
```bash
# Instalar Chromium para Playwright (requerido para tests E2E con browser)
uv run playwright install chromium
```

### EjecuciÃ³n Interactiva (Recomendado)
Simplemente ejecuta el motor y sigue al asistente visual:
```bash
uv run uif-scraper --setup
```

### EjecuciÃ³n AutomÃ¡tica (CLI)
Para flujos de trabajo automatizados o scripts de shell:
```bash
uv run uif-scraper https://ejemplo.com --workers 10 --scope smart
```

---

## ğŸ“ ESTRUCTURA DE SALIDA

Cada proyecto genera una cÃ¡psula de datos independiente:

```text
data/
â””â”€â”€ dominio_com/
    â”œâ”€â”€ content/              # Markdown puro de pÃ¡ginas web
    â”œâ”€â”€ media/
    â”‚   â”œâ”€â”€ images/           # Assets visuales descargados
    â”‚   â””â”€â”€ docs/             # PDFs/Office + sus espejos .md
    â”œâ”€â”€ state_dominio_com.db  # Base de datos de estado (WAL)
    â””â”€â”€ migration_audit.jsonl # AuditorÃ­a de bajo nivel
```

---

## ğŸ§ª MANTENIMIENTO

Para realizar una purga controlada del entorno de datos y caches antes de una nueva migraciÃ³n:
```bash
uv run clean.py
```

---

**Arquitecto:** "En UIF, no scrapeamos datos; curamos conocimiento. Cada archivo generado es una seÃ±al pura lista para ser comprendida por la prÃ³xima generaciÃ³n de IAs."
