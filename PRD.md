Aqu铆 tienes el **Product Requirements Document (PRD)** para la actualizaci贸n del *Universal Ingestion Framework*, incorporando y aprobando todas las notas cr铆ticas, medias y bajas identificadas en la auditor铆a t茅cnica.

---

#  PRD: Universal Ingestion Framework v4.0 "Resilience & Scale"

**Estado:** Borrador Aprobado para Desarrollo
**Fecha:** 24 de Mayo de 2024
**Prioridad:** Cr铆tica (Bloqueante para Producci贸n)

---

## 1. Resumen Ejecutivo

La versi贸n actual del *Universal Ingestion Framework* (v3.x) presenta una arquitectura s贸lida pero carece de mecanismos cr铆ticos de seguridad, estabilidad de memoria y cumplimiento legal, impidiendo su despliegue en entornos de producci贸n reales. Este PRD define los requisitos para la versi贸n 4.0, enfoc谩ndose en eliminar cuellos de botella de memoria, asegurar el cumplimiento 茅tico/legal y mejorar la resiliencia del sistema.

**Objetivo Principal:** Elevar la calificaci贸n del proyecto de 67/100 a >90/100, garantizando estabilidad en escenarios de alta carga.

---

## 2. Objetivos Clave (KPIs)

| M茅trica | Estado Actual (v3.x) | Objetivo (v4.0) |
| :--- | :--- | :--- |
| **Estabilidad de Memoria** | OOM con >100k URLs | Uso estable <500MB para 1M URLs |
| **Cumplimiento Legal** | No verifica `robots.txt` | Cumplimiento autom谩tico por defecto |
| **Seguridad** | SSL deshabilitado | SSL/TLS forzado con validaci贸n completa |
| **Calidad de Datos** | CAPTCHA procesado como contenido | Detecci贸n y exclusi贸n de CAPTCHA >95% |
| **Concurrencia** | Race conditions en DB | Operaciones at贸micas y Lock de misi贸n |

---

## 3. Alcance de los Cambios

### 3.1. Cambios Aprobados (Basados en Auditor铆a)

Se aprueban e incluyen en este sprint las 25 notas de la auditor铆a, priorizadas en tres fases de implementaci贸n.

####  FASE 1: Correcciones Cr铆ticas (Bloqueantes)

*Estos cambios son obligatorios para el pase a producci贸n.*

1. **Refactor de Memoria (`seen_urls`):**
    - **Problema:** `set[str]` ilimitado causa OOM.
    - **Requisito:** Reemplazar `seen_urls` y `seen_assets` con `TTLCache` (cachetools) o una soluci贸n respaldada por DB.
    - **Archivo:** `engine_core.py:186-187`.

2. **Cumplimiento Legal (`robots.txt`):**
    - **Problema:** Riesgo legal por ignorar directivas.
    - **Requisito:** Implementar `RobotsChecker` as铆ncrono. Por defecto `respect_robots_txt = True`.
    - **Archivo:** Nuevo archivo `utils/robots_checker.py`.

3. **Seguridad SSL:**
    - **Problema:** `ssl=False` vulnerable a MITM.
    - **Requisito:** Habilitar verificaci贸n SSL usando `certifi`. Eliminar flag `ssl=False`.
    - **Archivo:** `utils/http_session.py`.

4. **Rate Limiting Expl铆cito:**
    - **Problema:** Riesgo de baneo de IP.
    - **Requisito:** Implementar `AdaptiveRateLimiter` con delay configurable y jitter.
    - **Archivo:** `engine_core.py`.

####  FASE 2: Mejoras de Calidad y Seguridad

*Estos cambios previenen corrupci贸n de datos y mejoran la fiabilidad.*

1. **Detecci贸n de CAPTCHA:**
    - **Requisito:** Implementar `CaptchaDetector` antes de la extracci贸n de contenido. No guardar p谩ginas que sean desaf铆os de seguridad.
    - **Archivo:** Nuevo archivo `utils/captcha_detector.py`.

2. **Atomicidad de Base de Datos:**
    - **Problema:** Race conditions en `increment_retry` y multi-instancia.
    - **Requisito:** Usar cl谩usula `RETURNING` en SQLite. Implementar `acquire_mission_lock` para prevenir ejecuci贸n simult谩nea sobre el mismo dominio.
    - **Archivo:** `db_manager.py`.

3. **Sanitizaci贸n de Logs:**
    - **Problema:** Tokens en URLs se guardan en logs.
    - **Requisito:** Implementar `sanitize_url_for_logging` para redactar par谩metros sensibles.
    - **Archivo:** `utils/url_utils.py`.

####  FASE 3: Mantenibilidad y Refactoring T茅cnico

*Deuda t茅cnica y mejora del c贸digo.*

1. **Refactoring de God Objects:**
    - Dividir `engine_core.py` (891 l铆neas) en `Orchestrator`, `WorkerPool` y `StatsTracker`.
    - Dividir `_extract_metadata_pure` en sub-clases especializadas.

2. **Extracci贸n de Constantes:**
    - Mover todos los "magic numbers" a `core/constants.py` con documentaci贸n justificativa.

---

## 4. Especificaciones Funcionales Detalladas

### RF-01: Sistema de Control de Memoria (TTL Cache)

**Descripci贸n:** El motor debe limitar la cantidad de URLs rastreadas en memoria activa.
**L贸gica:**

- Utilizar `TTLCache` con un l铆mite de 100,000 entradas y TTL de 1 hora.
- Si una URL sale del cach茅, se verifica su estado en la base de datos antes de procesar.
**Criterio de Aceptaci贸n:** El consumo de RAM permanece estable al procesar 500,000 URLs.

### RF-02: Motor de Cumplimiento (Robots.txt)

**Descripci贸n:** El scraper debe respetar las reglas definidas en `/robots.txt` antes de realizar cualquier petici贸n.
**L贸gica:**

- Cacheo de parsers `robots.txt` por dominio (TTL 1 hora).
- Si `Disallow: /` existe para el path, marcar URL como `SKIPPED_ROBOTS` en DB y no procesar.
**Criterio de Aceptaci贸n:** Logs muestran omisi贸n de URLs bloqueadas. Tests unitarios validan reglas comunes.

### RF-03: Detecci贸n de Contenido Anti-Scraping

**Descripci贸n:** Identificar y aislar p谩ginas que presentan desaf铆os CAPTCHA o errores de verificaci贸n.
**Firmas Detectadas:** Cloudflare, reCAPTCHA, hCaptcha.
**Acci贸n:** Si se detecta CAPTCHA con confianza > 0.8, marcar URL como `BLOCKED_CAPTCHA` y no generar archivo Markdown.
**Criterio de Aceptaci贸n:** No se generan archivos `.md` que contengan c贸digo HTML de CAPTCHA.

---

## 5. Especificaciones T茅cnicas (No Funcionales)

### RNF-01: Rendimiento

- **Bloqueo de Event Loop:** Las operaciones CPU-bound (limpieza HTML, compresi贸n) deben ejecutarse en un `ThreadPoolExecutor` dedicado para no bloquear el loop async.
- **Paginaci贸n:** `db_manager.get_pending_urls` debe usar `LIMIT` y `OFFSET` obligatorios.

### RNF-02: Seguridad

- **SSL:** Conexiones a sitios con certificados inv谩lidos deben fallar de inmediato (a menos que se configure expl铆citamente un entorno de desarrollo inseguro, pero nunca por defecto).
- **PII:** Los archivos de log no deben contener par谩metros de URL sensibles (tokens, session_ids).

### RNF-03: Concurrencia

- **Lock de Misi贸n:** Solo una instancia del scraper puede procesar un dominio espec铆fico a la vez, utilizando bloqueos a nivel de DB o Redis.

---

## 6. Plan de Implementaci贸n y Cronograma

| Sprint | Duraci贸n | Actividades Clave | Entregable |
| :--- | :--- | :--- | :--- |
| **Sprint 1** | 3 d铆as | Fixes de Memoria, SSL, Robots.txt | Versi贸n 4.0-alpha (Estable) |
| **Sprint 2** | 3 d铆as | CAPTCHA Det., Rate Limiter, Atomic DB | Versi贸n 4.0-beta (Segura) |
| **Sprint 3** | 3 d铆as | Refactoring c贸digo, Constantes, Docs | Versi贸n 4.0-rc (Release Candidate) |
| **Sprint 4** | 2 d铆as | Testing E2E masivo, ajustes finales | **Release v4.0** |

---

## 7. Casos de Prueba (Testing)

1. **Test de Carga:** Ejecutar scraper contra un sitio espejo con 200k URLs. Verificar que la memoria RAM no supere el umbral definido.
2. **Test Legal:** Configurar un servidor mock con `robots.txt` restrictivo. Verificar que el scraper no descarga ninguna p谩gina prohibida.
3. **Test de CAPTCHA:** Apuntar el scraper a un sitio protegido por Cloudflare. Verificar que detecta el desaf铆o y no guarda el HTML del desaf铆o.
4. **Test de Multi-instancia:** Lanzar dos procesos simult谩neos contra el mismo dominio. Verificar que uno adquiere el lock y el otro se retira gracefully o espera.

---

## 8. Aprobaci贸n Final

Con este PRD, se aprueba la refactorizaci贸n y actualizaci贸n del c贸digo base. Se autoriza la inversi贸n de tiempo estimada (aprox. 64 horas / 8 d铆as h谩biles) para llevar el proyecto a un estado de "Producci贸n Lista".

**Firma del Arquitecto:** *Aprobado.*
**Fecha:** 24/05/2024

---

*Este documento sirve como la 煤nica fuente de verdad para el equipo de desarrollo durante el ciclo de actualizaci贸n v4.0.*
