# PRD: Refactorizaci√≥n Arquitect√≥nica - Argelia Scraper v3.0

**Documento de Requisitos de Producto - Nivel Production**  
**Fecha:** 2026-01-19  
**Autor:** Neo (Arquitecto Senior)  
**Estado:** Draft para Revisi√≥n  
**Prioridad:** P0 (Bloqueante para Escalabilidad)

---

## üìã √çNDICE

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Contexto y Justificaci√≥n](#contexto-y-justificaci√≥n)
3. [Objetivos T√©cnicos](#objetivos-t√©cnicos)
4. [Arquitectura Propuesta](#arquitectura-propuesta)
5. [Plan de Implementaci√≥n](#plan-de-implementaci√≥n)
6. [Testing y QA](#testing-y-qa)
7. [M√©tricas de √âxito](#m√©tricas-de-√©xito)
8. [Riesgos y Mitigaci√≥n](#riesgos-y-mitigaci√≥n)
9. [Timeline y Recursos](#timeline-y-recursos)

---

## 1. RESUMEN EJECUTIVO

### 1.1 Problema Actual

El scraper actual (v2.2) funciona pero presenta **deuda t√©cnica cr√≠tica** que impide:
- Escalabilidad m√°s all√° de 10 workers concurrentes
- Mantenimiento por equipos distribuidos
- Testing automatizado
- Configuraci√≥n flexible entre entornos

### 1.2 Soluci√≥n Propuesta

Refactorizaci√≥n completa hacia una **arquitectura modular** siguiendo principios SOLID, con:
- Sistema de configuraci√≥n persistente (XDG-compliant)
- Connection pooling para SQLite
- Separaci√≥n de responsabilidades en m√≥dulos independientes
- Logging profesional con rotaci√≥n
- Suite de tests unitarios y de integraci√≥n

### 1.3 Impacto Esperado

| M√©trica | Antes | Despu√©s | Mejora |
|---------|-------|---------|--------|
| Workers concurrentes estables | 5 | 20 | +300% |
| Tiempo de onboarding (nuevo dev) | 4 horas | 30 min | -87% |
| Cobertura de tests | 0% | 85% | ‚àû |
| Configuraci√≥n entre entornos | Manual | Autom√°tica | N/A |

---

## 2. CONTEXTO Y JUSTIFICACI√ìN

### 2.1 Estado Actual del C√≥digo

**Archivo Monol√≠tico:** 850 l√≠neas en un solo archivo  
**Acoplamiento:** Alto (todas las clases dependen entre s√≠)  
**Configuraci√≥n:** Hardcodeada en constantes globales  
**Persistencia:** Conexiones SQLite sin pool  
**Logging:** JSONL sin rotaci√≥n (riesgo de saturar disco)

### 2.2 Pain Points Identificados

#### üî¥ Cr√≠tico
1. **PATH hardcodeado sin alternativas** ‚Üí Usuarios no pueden elegir destino
2. **DNS override espec√≠fico de un sitio** ‚Üí Falla silenciosamente en otros dominios
3. **Fuga de conexiones SQLite** ‚Üí Race conditions con >10 workers
4. **Logging sin l√≠mite** ‚Üí Archivos de 8GB+ observados en producci√≥n

#### üü° Alto
5. **Mezcla de responsabilidades** ‚Üí Clase Engine hace 7 cosas distintas
6. **Sin tests** ‚Üí Imposible refactorizar con confianza
7. **Configuraci√≥n no persistente** ‚Üí Cada ejecuci√≥n pide lo mismo

#### üü¢ Medio
8. **Duplicaci√≥n de l√≥gica de limpieza HTML** ‚Üí 3 funciones hacen cosas similares
9. **Manejo de errores inconsistente** ‚Üí Algunos se loguean, otros se ignoran
10. **Sin telemetr√≠a** ‚Üí No sabemos d√≥nde se gasta el tiempo real

### 2.3 ¬øPor Qu√© Ahora?

- **Adopci√≥n creciente:** 3 equipos internos quieren usar el scraper
- **Caso de uso cr√≠tico:** Migraci√≥n de 50K+ p√°ginas de cliente enterprise
- **Deuda t√©cnica acumulada:** Cada hotfix a√±ade m√°s complejidad

---

## 3. OBJETIVOS T√âCNICOS

### 3.1 Objetivos Primarios (MUST HAVE)

#### OBJ-1: Sistema de Configuraci√≥n Profesional
**Descripci√≥n:** Implementar gesti√≥n de config siguiendo XDG Base Directory Spec  
**Criterio de √âxito:**
- [ ] Config cargable desde archivo YAML
- [ ] Variables de entorno tienen prioridad sobre archivo
- [ ] Wizard interactivo en primera ejecuci√≥n
- [ ] Validaci√≥n con Pydantic
- [ ] Paths expandibles (`~`, variables de entorno)

**Archivo:** `argelia_scraper/config.py`

**Schema Config:**
```python
class ScraperConfig(BaseModel):
    data_dir: Path                    # D√≥nde se guardan resultados
    cache_dir: Path                   # Cache temporal
    max_retries: int = 3              # Reintentos por URL
    timeout_seconds: int = 30         # Timeout HTTP
    default_workers: int = 5          # Concurrencia por defecto
    asset_workers: int = 8            # Workers espec√≠ficos para assets
    dns_overrides: dict[str, str]     # Opcional: {"domain.com": "1.2.3.4"}
    log_rotation_mb: int = 50         # Tama√±o antes de rotar logs
    log_level: str = "INFO"           # DEBUG|INFO|WARNING|ERROR
```

**Ubicaciones de b√∫squeda (en orden):**
1. `--config /ruta/personalizada/config.yaml` (CLI arg)
2. `$XDG_CONFIG_HOME/argelia-scraper/config.yaml`
3. `~/.config/argelia-scraper/config.yaml`
4. `/etc/argelia-scraper/config.yaml`
5. Valores por defecto (hardcoded)

**Variable de entorno para override:**
```bash
export SCRAPER_DATA_DIR=/mnt/external/scrapes
export SCRAPER_MAX_WORKERS=20
```

---

#### OBJ-2: Connection Pool para SQLite
**Descripci√≥n:** Evitar race conditions y mejorar throughput de DB  
**Criterio de √âxito:**
- [ ] Pool reutilizable de N conexiones (default: 5)
- [ ] Context manager async para acquire/release
- [ ] Configuraci√≥n WAL + NORMAL synchronous
- [ ] Timeout configurable por conexi√≥n
- [ ] Cleanup autom√°tico al finalizar

**Archivo:** `argelia_scraper/db_pool.py`

**API Propuesta:**
```python
class SQLitePool:
    async def acquire(self) -> aiosqlite.Connection
    async def close_all(self) -> None
    
# Uso en StateManager:
async with self.pool.acquire() as db:
    await db.execute(...)
```

**Configuraci√≥n de SQLite:**
```sql
PRAGMA journal_mode=WAL;          -- Write-Ahead Logging
PRAGMA synchronous=NORMAL;        -- Balance seguridad/velocidad
PRAGMA cache_size=-64000;         -- 64MB de cache
PRAGMA busy_timeout=5000;         -- 5s antes de fallar
```

---

#### OBJ-3: Separaci√≥n de Responsabilidades (Modular Architecture)
**Descripci√≥n:** Dividir el monolito en m√≥dulos especializados  
**Criterio de √âxito:**
- [ ] Cada m√≥dulo tiene una responsabilidad √∫nica
- [ ] Testeable en aislamiento
- [ ] Interfaces claras entre m√≥dulos
- [ ] Sin dependencias circulares

**Estructura de Archivos:**
```
argelia_scraper/
‚îú‚îÄ‚îÄ __init__.py                 # Exports p√∫blicos
‚îú‚îÄ‚îÄ config.py                   # ScraperConfig
‚îú‚îÄ‚îÄ db_pool.py                  # SQLitePool
‚îú‚îÄ‚îÄ db_manager.py               # StateManager
‚îú‚îÄ‚îÄ models.py                   # Pydantic models (WebPage, etc.)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ url_utils.py            # smart_url_normalize, slugify
‚îÇ   ‚îú‚îÄ‚îÄ html_cleaner.py         # pre_clean_html, prune_by_density
‚îÇ   ‚îî‚îÄ‚îÄ text_utils.py           # ftfy wrappers, sanitizaci√≥n
‚îú‚îÄ‚îÄ extractors/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # BaseExtractor (interface)
‚îÇ   ‚îú‚îÄ‚îÄ text_extractor.py       # Trafilatura + MarkItDown
‚îÇ   ‚îú‚îÄ‚îÄ metadata_extractor.py   # Open Graph, Schema.org
‚îÇ   ‚îî‚îÄ‚îÄ asset_extractor.py      # Descarga im√°genes/PDFs
‚îú‚îÄ‚îÄ engine.py                   # ArgeliaMigrationEngine (orquestador)
‚îú‚îÄ‚îÄ cli.py                      # main() + argparse + wizard
‚îî‚îÄ‚îÄ version.py                  # __version__ = "3.0.0"
```

**Dependencias entre M√≥dulos:**
```
cli.py ‚Üí engine.py ‚Üí [extractors/*, db_manager.py]
                  ‚Üí config.py
                  ‚Üí db_pool.py
```

---

#### OBJ-4: Logging Profesional
**Descripci√≥n:** Sistema de logs enterprise con rotaci√≥n y niveles  
**Criterio de √âxito:**
- [ ] Rotaci√≥n autom√°tica por tama√±o
- [ ] Compresi√≥n de logs antiguos
- [ ] Retenci√≥n configurable
- [ ] Formato estructurado (JSON para parseo)
- [ ] Niveles de log respetados

**Implementaci√≥n:**
```python
from loguru import logger

logger.add(
    config.data_dir / "scraper_{time:YYYY-MM-DD}.log",
    rotation=f"{config.log_rotation_mb} MB",
    retention="10 days",
    compression="zip",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
    level=config.log_level,
    enqueue=True,  # Thread-safe
)
```

**Estructura de Logs:**
```json
{
  "timestamp": "2026-01-19T14:30:00Z",
  "level": "INFO",
  "module": "engine",
  "function": "process_page",
  "message": "P√°gina procesada exitosamente",
  "context": {
    "url": "https://ejemplo.com/page1",
    "duration_ms": 1234,
    "markdown_size": 45678
  }
}
```

---

### 3.2 Objetivos Secundarios (SHOULD HAVE)

#### OBJ-5: Suite de Tests
**Descripci√≥n:** Cobertura m√≠nima del 85% en m√≥dulos cr√≠ticos  
**Framework:** pytest + pytest-asyncio + pytest-cov

**Estructura:**
```
tests/
‚îú‚îÄ‚îÄ conftest.py                 # Fixtures globales
‚îú‚îÄ‚îÄ test_config.py              # Tests de ScraperConfig
‚îú‚îÄ‚îÄ test_db_pool.py             # Tests de SQLitePool
‚îú‚îÄ‚îÄ test_url_utils.py           # Tests de normalizaci√≥n
‚îú‚îÄ‚îÄ test_html_cleaner.py        # Tests de limpieza
‚îú‚îÄ‚îÄ test_extractors/
‚îÇ   ‚îú‚îÄ‚îÄ test_text.py
‚îÇ   ‚îú‚îÄ‚îÄ test_metadata.py
‚îÇ   ‚îî‚îÄ‚îÄ test_assets.py
‚îî‚îÄ‚îÄ integration/
    ‚îî‚îÄ‚îÄ test_full_scrape.py     # Test end-to-end
```

**Fixtures Requeridos:**
```python
@pytest.fixture
async def test_config():
    """Config temporal para tests"""
    
@pytest.fixture
async def mock_html_response():
    """HTML de prueba controlado"""
    
@pytest.fixture
async def temp_db():
    """SQLite en memoria para tests"""
```

---

#### OBJ-6: Telemetr√≠a y Profiling
**Descripci√≥n:** M√©tricas internas para optimizaci√≥n  
**Criterio de √âxito:**
- [ ] Tiempo promedio por p√°gina
- [ ] Distribuci√≥n de errores por tipo
- [ ] Uso de memoria por worker
- [ ] Throughput de DB (queries/seg)

**Implementaci√≥n con Prometheus (opcional):**
```python
from prometheus_client import Counter, Histogram

pages_processed = Counter('pages_processed_total', 'Total pages scraped')
page_duration = Histogram('page_processing_seconds', 'Time to process page')
```

---

## 4. ARQUITECTURA PROPUESTA

### 4.1 Diagrama de Componentes

```
```
SEMANA 1: Fundaci√≥n
‚îú‚îÄ D√≠a 1-2: Estructura modular + ScraperConfig
‚îú‚îÄ D√≠a 3-4: SQLitePool + Tests
‚îî‚îÄ D√≠a 5: Logging setup + Documentaci√≥n

SEMANA 2: Separaci√≥n de Responsabilidades  
‚îú‚îÄ D√≠a 1-2: Utils (URL, HTML, Text)
‚îú‚îÄ D√≠a 3-4: Extractors (Text, Metadata, Assets)
‚îî‚îÄ D√≠a 5: StateManager refactor + Integration tests

SEMANA 3: Integraci√≥n y Optimizaci√≥n
‚îú‚îÄ D√≠a 1-2: Engine refactor + Dependency injection
‚îú‚îÄ D√≠a 3: Pipeline optimization
‚îú‚îÄ D√≠a 4: DNS override configurable
‚îî‚îÄ D√≠a 5: Performance benchmarks

SEMANA 4: Testing y Hardening
‚îú‚îÄ D√≠a 1-2: Suite completa de tests
‚îú‚îÄ D√≠a 3: Error handling + Circuit breakers
‚îú‚îÄ D√≠a 4: Documentaci√≥n completa
‚îî‚îÄ D√≠a 5: Release Candidate + Beta testing

SEMANA 5: Release y Rollout (Buffer)
‚îú‚îÄ D√≠a 1-2: Fixes de beta testing
‚îú‚îÄ D√≠a 3: Migration guide final
‚îú‚îÄ D√≠a 4: Release v3.0.0
‚îî‚îÄ D√≠a 5: Post-release monitoring
```

### 9.2 Recursos Necesarios

#### Equipo Core

| Rol | Dedicaci√≥n | Horas/Semana | Total Horas |
|-----|-----------|--------------|-------------|
| **Senior Backend Engineer** | 100% | 40h | 200h |
| **QA Engineer** | 50% | 20h | 100h |
| **Tech Writer** | 20% | 8h | 40h |
| **Tech Lead (Reviewer)** | 10% | 4h | 20h |
| **TOTAL** | - | **72h/semana** | **360h** |

#### Herramientas y Servicios

**Desarrollo:**
- ‚úÖ GitHub (Ya disponible)
- ‚úÖ GitHub Actions (CI/CD) - Plan Free suficiente
- ‚ö†Ô∏è **Requerido:** pytest-cov, pre-commit, mypy (instalar con uv)

**Monitoreo Post-Release:**
- üü° **Opcional pero Recomendado:** Sentry (Free tier: 5K eventos/mes)
- üü° **Opcional:** Datadog o similar (para profiling en producci√≥n)

**Costo Estimado:**
- Herramientas: $0 (usando free tiers)
- Infraestructura: $0 (desarrollo local + GitHub Actions)
- **Costo Total Monetario: $0**

#### Hardware M√≠nimo (Para Load Testing)

```yaml
Test Machine:
  CPU: 4 cores m√≠nimo (8 recomendado para 20 workers)
  RAM: 8GB m√≠nimo (16GB recomendado)
  Storage: 50GB libres (para test de 10K URLs)
  Network: 100Mbps+ (para simular scraping real)
```

---

### 9.3 Dependencias Cr√≠ticas Entre Fases

```
FASE 1 (Fundaci√≥n)
‚îî‚îÄ üîí Bloqueante para FASE 2
   ‚îî‚îÄ Requerido: SQLitePool funcionando
   ‚îî‚îÄ Requerido: ScraperConfig validado

FASE 2 (Modularizaci√≥n)  
‚îî‚îÄ üîí Bloqueante para FASE 3
   ‚îî‚îÄ Requerido: Extractors testeados
   ‚îî‚îÄ Requerido: 0 dependencias circulares

FASE 3 (Optimizaci√≥n)
‚îî‚îÄ üîí Bloqueante para FASE 4
   ‚îî‚îÄ Requerido: Throughput >50 p√°g/min
   ‚îî‚îÄ Requerido: Engine refactorizado

FASE 4 (Testing)
‚îî‚îÄ üîí Bloqueante para RELEASE
   ‚îî‚îÄ Requerido: Cobertura >85%
   ‚îî‚îÄ Requerido: Load test passing
```

**REGLA DE ORO:** 
No se puede empezar una fase hasta que la anterior tenga **todos sus tests passing** y **code review aprobado**.

---

### 9.4 Puntos de Validaci√≥n (Checkpoints)

**Estos son momentos OBLIGATORIOS de pausa para validaci√≥n:**

#### ‚ö†Ô∏è Checkpoint 1.1 - Fin D√≠a 1
**Validaci√≥n:** ¬øEstructura modular creada correctamente?  
**Criterio:** `pytest` debe encontrar y ejecutar tests dummy  
**Responsable:** Tech Lead  
**Tiempo:** 30 minutos

#### ‚ö†Ô∏è Checkpoint 1.5 - Fin Semana 1  
**Validaci√≥n:** ¬øFundaci√≥n s√≥lida?  
**Criterio:** 
- Config funcional con wizard
- Pool probado con 100 queries concurrentes
- Logging rotando correctamente  
**Responsable:** Tech Lead + QA  
**Tiempo:** 1 hora (incluye demo)

#### ‚ö†Ô∏è Checkpoint 2.5 - Fin Semana 2
**Validaci√≥n:** ¬øM√≥dulos independientes?  
**Criterio:**
- Cada extractor puede usarse standalone
- StateManager no tiene c√≥digo duplicado
- 0 dependencias circulares (verificar con `pydeps`)  
**Responsable:** Tech Lead  
**Tiempo:** 1 hora

#### ‚ö†Ô∏è Checkpoint 3.4 - Jueves Semana 3
**Validaci√≥n:** ¬øPerformance aceptable?  
**Criterio:**
- Throughput >50 p√°g/min en benchmark de 1000 URLs
- Uso de memoria <2GB con 20 workers  
**Responsable:** QA + Tech Lead  
**Tiempo:** 2 horas (incluye profiling)

#### ‚ö†Ô∏è Checkpoint 4.5 - Viernes Semana 4
**Validaci√≥n:** ¬øListo para Beta?  
**Criterio:**
- Cobertura >85%
- Load test (10K URLs) sin crashes
- Documentaci√≥n completa  
**Responsable:** Todo el equipo  
**Tiempo:** 2 horas (Go/No-Go meeting)

#### ‚ö†Ô∏è Checkpoint 5.2 - Martes Semana 5
**Validaci√≥n:** ¬øListo para Release?  
**Criterio:**
- Fixes de beta completados
- Smoke tests en 3 OS passing
- Release notes aprobadas  
**Responsable:** Product Owner + Tech Lead  
**Tiempo:** 1 hora (Final Go/No-Go)

---

### 9.5 Plan de Contingencia (Buffers)

**Escenario 1: Un m√≥dulo cr√≠tico falla en testing**  
**Tiempo perdido:** 1-2 d√≠as  
**Acci√≥n:**
- Asignar Senior BE al 100% en ese m√≥dulo
- Posponer features no-cr√≠ticos de siguiente fase
- Usar D√≠a 5 de cada semana como buffer

**Escenario 2: Load test falla en Semana 4**  
**Tiempo perdido:** 2-3 d√≠as  
**Acci√≥n:**
- Activar Semana 5 como buffer completo
- Priorizar solo fixes de performance
- Considerar release como v3.0.0-beta si no se resuelve

**Escenario 3: Enfermedad/Ausencia de BE**  
**Tiempo perdido:** Variable  
**Acci√≥n:**
- QA asume tareas de testing simples
- Tech Lead asume desarrollo cr√≠tico (temporal)
- Extender timeline 1 semana si ausencia >3 d√≠as

**Escenario 4: Scope creep (Features nuevos solicitados)**  
**Acci√≥n:**
- **NO se aceptan features nuevos** durante refactorizaci√≥n
- Crear tickets en backlog para v3.1
- Mantener foco en objetivos del PRD

---

### 9.6 Estimaci√≥n de Esfuerzo (Story Points)

**Conversi√≥n:** 1 Story Point = 4 horas de trabajo efectivo

| Fase | Tasks | Story Points | Horas | D√≠as (8h) |
|------|-------|--------------|-------|-----------|
| FASE 1: Fundaci√≥n | 12 | 20 SP | 80h | 10 d√≠as |
| FASE 2: Modularizaci√≥n | 18 | 32 SP | 128h | 16 d√≠as |
| FASE 3: Optimizaci√≥n | 14 | 24 SP | 96h | 12 d√≠as |
| FASE 4: Testing | 16 | 20 SP | 80h | 10 d√≠as |
| FASE 5: Release | 8 | 8 SP | 32h | 4 d√≠as |
| **TOTAL** | **68** | **104 SP** | **416h** | **52 d√≠as** |

**Con equipo de 72h/semana efectivas:**
- Timeline te√≥rico: 416h / 72h = **5.8 semanas**
- Timeline con buffer (20%): **7 semanas** ‚úÖ

**Conclusi√≥n:** El cronograma de 5 semanas es **ajustado pero realista** si:
- No hay scope creep
- El equipo est√° 100% dedicado
- Los checkpoints se respetan

---

### 9.7 Calendario Real (Fechas Absolutas)

**Fecha de Inicio:** Lunes 20 de Enero, 2026

| Semana | Fechas | Fase | Entregable |
|--------|--------|------|------------|
| **W1** | 20-24 Enero | Fundaci√≥n | feat/foundation branch |
| **W2** | 27-31 Enero | Modularizaci√≥n | feat/modularization branch |
| **W3** | 3-7 Febrero | Optimizaci√≥n | feat/optimization branch |
| **W4** | 10-14 Febrero | Testing | v3.0.0-rc1 |
| **W5** | 17-21 Febrero | Release | **v3.0.0 GA** üöÄ |

**Release Target:** Viernes 21 de Febrero, 2026

**Festivos/D√≠as no laborables (ajustar seg√∫n regi√≥n):**
- ‚ö†Ô∏è Verificar calendario local antes de confirmar fechas
- A√±adir 1 semana de buffer si hay festivos en este rango

---

### 9.8 Comunicaci√≥n y Reportes

**Daily Standup:** 09:00 AM (15 minutos)
- ¬øQu√© hice ayer?
- ¬øQu√© har√© hoy?
- ¬øTengo blockers?

**Weekly Demo:** Viernes 16:30 (30 minutos)
- Demo del milestone alcanzado
- M√©tricas de progreso (cobertura, performance)
- Decisiones para siguiente semana

**Checkpoint Reviews:** Seg√∫n calendario (1-2 horas)
- Formato: Presentaci√≥n t√©cnica + Q&A
- Aprobadores deben estar presentes
- Salida: Go/No-Go expl√≠cito

**Canales de Comunicaci√≥n:**
```
Slack:
  #argelia-refactor        ‚Üí Updates diarios
  #argelia-alerts          ‚Üí Errores cr√≠ticos de CI/CD

GitHub:
  Issues                   ‚Üí Bugs y tasks
  Pull Requests            ‚Üí Code reviews
  Projects (Kanban)        ‚Üí Tracking visual
  
Email:
  Weekly Summary           ‚Üí Stakeholders no-t√©cnicos
```

---

## 10. CHECKLIST DE ENTREGA

### 10.1 Definition of Done (DoD)

#### C√≥digo
- [ ] Todos los m√≥dulos en estructura propuesta
- [ ] 0 warnings de mypy (type checking)
- [ ] 0 errores de pylint (score >9.0)
- [ ] Formatted con black + isort
- [ ] Sin TODOs en c√≥digo de producci√≥n

#### Tests
- [ ] Cobertura >85% en core modules
- [ ] 3 tests de integraci√≥n passing
- [ ] 1 load test documentado (10K URLs)
- [ ] CI/CD verde en todas las branches

#### Documentaci√≥n
- [ ] README.md actualizado
- [ ] MIGRATION_GUIDE.md completo
- [ ] API reference (autogenerada con Sphinx)
- [ ] Changelog siguiendo Keep a Changelog

#### Release
- [ ] Tag de versi√≥n `v3.0.0`
- [ ] PyPI package publicado
- [ ] Docker image actualizado
- [ ] Anuncio en canales internos

---

## 11. POST-LAUNCH

### 11.1 Monitoreo (Primeras 2 Semanas)

**M√©tricas a Observar:**
```python
# Dashboard Sentry/Datadog
- Error rate (target: <0.1%)
- P95 latency (target: <5s)
- Memory usage (target: <2GB)
- Crash rate (target: 0)
```

**Alertas:**
- Error rate >1% ‚Üí Slack alert inmediato
- Memory >3GB ‚Üí Investigar leak
- Crash ‚Üí Rollback autom√°tico a v2.2

### 11.2 Iteraciones Post-Launch

**v3.1 (1 mes despu√©s):**
- Optimizaciones basadas en telemetr√≠a real
- Features solicitados por early adopters

**v3.2 (3 meses despu√©s):**
- Soporte para PostgreSQL (alternativa a SQLite)
- API REST para integraci√≥n con otros sistemas

---

## 12. AP√âNDICES

### A. Glosario T√©cnico

| T√©rmino | Definici√≥n |
|---------|-----------|
| **XDG** | X Desktop Group - Est√°ndar para ubicaci√≥n de archivos config en Linux |
| **WAL** | Write-Ahead Logging - Modo de journaling de SQLite |
| **Connection Pool** | Conjunto reutilizable de conexiones DB para reducir overhead |
| **Circuit Breaker** | Patr√≥n que previene llamadas a servicios fallando |
| **Backoff Exponencial** | Estrategia de retry con delays crecientes (1s, 2s, 4s...) |

### B. Referencias

- [XDG Base Directory Spec](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html)
- [SQLite WAL Mode](https://www.sqlite.org/wal.html)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [pytest Best Practices](https://docs.pytest.org/en/stable/goodpractices.html)

### C. Decisiones de Arquitectura (ADRs)

#### ADR-001: ¬øPor Qu√© SQLite en Lugar de PostgreSQL?
**Contexto:** Necesitamos persistencia para estado de URLs  
**Decisi√≥n:** SQLite con WAL mode  
**Razones:**
- Zero-config (no requiere servidor externo)
- Suficiente para <100K URLs
- File-based = F√°cil backup/restauraci√≥n
- Pool de conexiones mitiga limitaciones

**Alternativa Descartada:** PostgreSQL  
**Motivo:** Overkill para caso de uso actual, a√±ade complejidad de deployment

#### ADR-002: ¬øLoguru vs Standard Logging?
**Contexto:** Necesitamos logging con rotaci√≥n  
**Decisi√≥n:** Loguru  
**Razones:**
- API m√°s simple que stdlib logging
- Rotaci√≥n built-in
- Thread-safe por defecto
- Mejor DX (developer experience)

**Alternativa Descartada:** stdlib logging + TimedRotatingFileHandler  
**Motivo:** Configuraci√≥n verbosa, sin compresi√≥n autom√°tica

---

## 13. FIRMA Y APROBACI√ìN

**Preparado por:** Neo (Arquitecto Senior)  
**Fecha:** 2026-01-19  

**Requiere Aprobaci√≥n de:**
- [ ] Tech Lead (Arquitectura)
- [ ] Engineering Manager (Timeline/Recursos)
- [ ] Product Owner (Priorizaci√≥n)

**Pr√≥ximo Paso:** Crear GitHub Project con tasks del PRD‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CLI Layer                     ‚îÇ
‚îÇ  (cli.py - Argumentos + Wizard + Output)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Configuration Layer                ‚îÇ
‚îÇ  (config.py - ScraperConfig + Validation)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Orchestration Layer               ‚îÇ
‚îÇ  (engine.py - ArgeliaMigrationEngine)           ‚îÇ
‚îÇ   - Gesti√≥n de colas                            ‚îÇ
‚îÇ   - Coordinaci√≥n de workers                     ‚îÇ
‚îÇ   - Progress tracking                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                   ‚îÇ
      ‚ñº                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Extraction Layer ‚îÇ           ‚îÇ Persistence Layer‚îÇ
‚îÇ  (extractors/*)  ‚îÇ           ‚îÇ  (db_manager.py) ‚îÇ
‚îÇ - Text           ‚îÇ           ‚îÇ  - StateManager  ‚îÇ
‚îÇ - Metadata       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  - SQLitePool    ‚îÇ
‚îÇ - Assets         ‚îÇ           ‚îÇ  - Transactions  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Utilities Layer                 ‚îÇ
‚îÇ  (utils/* - URL, HTML, Text processing)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Flujo de Datos

```
1. Usuario ejecuta CLI
   ‚Üì
2. CLI carga config (archivo/env/wizard)
   ‚Üì
3. Engine inicializa con config
   ‚Üì
4. StateManager crea/conecta DB via Pool
   ‚Üì
5. Engine puebla colas desde DB
   ‚Üì
6. Workers procesan URLs en paralelo:
   a. Fetcher descarga contenido
   b. HTMLCleaner poda basura
   c. TextExtractor ‚Üí Markdown
   d. MetadataExtractor ‚Üí Frontmatter
   e. AssetExtractor ‚Üí Descarga media
   ‚Üì
7. StateManager actualiza progreso en DB
   ‚Üì
8. Engine genera reporte final
```

### 4.3 Interfaces Cr√≠ticas

#### IExtractor (Base para todos los extractors)
```python
from abc import ABC, abstractmethod

class IExtractor(ABC):
    @abstractmethod
    async def extract(self, content: str, url: str) -> dict:
        """
        Extrae informaci√≥n espec√≠fica del contenido
        
        Args:
            content: HTML crudo o respuesta HTTP
            url: URL original (para contexto)
        
        Returns:
            Dict con datos extra√≠dos (estructura espec√≠fica por tipo)
        """
        pass
```

#### IStateManager (Contrato de persistencia)
```python
class IStateManager(ABC):
    @abstractmethod
    async def add_url(self, url: str, status: MigrationStatus) -> None:
        pass
    
    @abstractmethod
    async def update_status(self, url: str, status: MigrationStatus) -> None:
        pass
    
    @abstractmethod
    async def get_pending_urls(self) -> List[str]:
        pass
```

---

## 5. PLAN DE IMPLEMENTACI√ìN

### 5.1 Fases del Proyecto

#### FASE 1: Fundaci√≥n (Semana 1)
**Objetivo:** Establecer infraestructura base sin romper funcionalidad actual

**Tareas:**
1. [ ] **Crear estructura de directorios modular**
   - Mover c√≥digo a `argelia_scraper/` package
   - Crear `__init__.py` con exports
   
2. [ ] **Implementar ScraperConfig completo**
   - Archivo: `config.py`
   - Tests: `tests/test_config.py`
   - Wizard interactivo funcional
   
3. [ ] **Implementar SQLitePool**
   - Archivo: `db_pool.py`
   - Tests: `tests/test_db_pool.py`
   - Benchmark: Comparar throughput antes/despu√©s
   
4. [ ] **Setup de logging con loguru**
   - Configurar rotaci√≥n
   - Migrar prints a logger
   
**Entregables:**
- Branch `feat/foundation` con tests passing
- Documento de migraci√≥n de config para usuarios actuales

---

#### FASE 2: Separaci√≥n de Responsabilidades (Semana 2)

**Objetivo:** Modularizar c√≥digo sin cambiar API p√∫blica

**Tareas:**
1. [ ] **Extraer Utils**
   - `utils/url_utils.py`: Mover `smart_url_normalize`, `slugify`
   - `utils/html_cleaner.py`: Mover `pre_clean_html`, `prune_by_density`
   - `utils/text_utils.py`: Wrappers de ftfy
   - Tests unitarios para cada funci√≥n
   
2. [ ] **Crear Extractors**
   - `extractors/base.py`: Interface `IExtractor`
   - `extractors/text_extractor.py`: L√≥gica Trafilatura + MarkItDown
   - `extractors/metadata_extractor.py`: Open Graph, Schema.org
   - `extractors/asset_extractor.py`: Descarga + conversi√≥n
   - Tests con HTML fixtures
   
3. [ ] **Refactorizar StateManager**
   - Integrar SQLitePool
   - Separar l√≥gica de queries en m√©todos privados
   - Agregar transacciones expl√≠citas
   
**Entregables:**
- Todos los m√≥dulos funcionando independientemente
- Cobertura de tests >80% en nuevos m√≥dulos

---

#### FASE 3: Integraci√≥n y Optimizaci√≥n (Semana 3)

**Objetivo:** Unir m√≥dulos y optimizar pipeline

**Tareas:**
1. [ ] **Refactorizar ArgeliaMigrationEngine**
   - Inyectar dependencias (config, state, extractors)
   - Delegar procesamiento a extractors
   - Simplificar l√≥gica de workers
   
2. [ ] **Optimizar Pipeline de Extracci√≥n**
   - Paralelizar extractors independientes
   - Cache de resultados de limpieza HTML
   - Batch inserts en DB
   
3. [ ] **Implementar DNS Override Configurable**
   - Leer de `config.dns_overrides`
   - Construir args de browser din√°micamente
   
**Entregables:**
- Engine refactorizado con 50% menos l√≠neas
- Benchmarks de rendimiento (antes/despu√©s)

---

#### FASE 4: Testing y Hardening (Semana 4)

**Objetivo:** Asegurar robustez y preparar para producci√≥n

**Tareas:**
1. [ ] **Suite de Tests Completa**
   - Tests unitarios: 85% cobertura
   - Tests de integraci√≥n: 3 escenarios cr√≠ticos
   - Tests de carga: 20 workers, 1000 URLs
   
2. [ ] **Manejo de Errores Mejorado**
   - Excepciones tipadas por categor√≠a
   - Retry con backoff exponencial
   - Circuit breaker para sitios problem√°ticos
   
3. [ ] **Documentaci√≥n**
   - README actualizado con nueva arquitectura
   - Docstrings en todos los m√≥dulos p√∫blicos
   - Gu√≠a de migraci√≥n desde v2.2
   
**Entregables:**
- Suite de tests passing al 100%
- Documentaci√≥n completa
- Release candidate v3.0.0-rc1

---

### 5.2 Estrategia de Migraci√≥n

#### Para Usuarios Actuales

**Opci√≥n 1: Migraci√≥n Manual (Recomendado)**
```bash
# 1. Backup del proyecto actual
cp -r scraper_v2 scraper_v2_backup

# 2. Instalar nueva versi√≥n
uv pip install argelia-scraper==3.0.0

# 3. Ejecutar wizard de config
argelia-scraper --setup

# 4. Migrar datos antiguos (script provisto)
python migrate_v2_to_v3.py --old-data ./data --new-config ~/.config/argelia-scraper/config.yaml
```

**Opci√≥n 2: Coexistencia (Transici√≥n Gradual)**
```bash
# Mantener v2.2 para proyectos en curso
python scraper_old.py --url https://sitio1.com

# Usar v3.0 para nuevos proyectos
argelia-scraper scrape --url https://sitio2.com
```

#### Breaking Changes

| Feature | v2.2 | v3.0 | Acci√≥n Requerida |
|---------|------|------|------------------|
| Path de datos | `./data` hardcoded | Configurable | Ejecutar wizard o set `SCRAPER_DATA_DIR` |
| CLI args | `--only-text` | `--extract text` | Actualizar scripts |
| DB schema | Sin versi√≥n | Versionado | Auto-migraci√≥n en primera ejecuci√≥n |
| Imports | `from scraper import Engine` | `from argelia_scraper import Engine` | Actualizar imports |

---

## 6. TESTING Y QA

### 6.1 Estrategia de Testing

#### Tests Unitarios (Target: 85% cobertura)
**Herramientas:** pytest, pytest-asyncio, pytest-cov

**M√≥dulos Cr√≠ticos:**
- [ ] `config.py`: 100% (carga, validaci√≥n, guardado)
- [ ] `db_pool.py`: 95% (acquire, release, cleanup)
- [ ] `utils/url_utils.py`: 100% (casos edge de URLs)
- [ ] `utils/html_cleaner.py`: 90% (distintos tipos de basura)
- [ ] `extractors/text_extractor.py`: 85% (formatos variados)

**Ejemplo de Test:**
```python
@pytest.mark.asyncio
async def test_url_normalize_double_encoding():
    """Verifica que no se encode dos veces"""
    url = "https://site.com/b√∫squeda?q=caf√© con leche"
    normalized = smart_url_normalize(url)
    
    # No debe tener %25 (encoding de %)
    assert "%25" not in normalized
    # Debe manejar tildes correctamente
    assert "caf%C3%A9" in normalized or "caf√©" in normalized
```

---

#### Tests de Integraci√≥n (Escenarios Cr√≠ticos)

**Escenario 1: Scraping End-to-End**
```python
@pytest.mark.integration
async def test_full_scrape_small_site(tmp_path):
    """Scraping completo de un sitio de 10 p√°ginas"""
    config = ScraperConfig(data_dir=tmp_path, default_workers=2)
    engine = ArgeliaMigrationEngine(config, url="http://example-test.com")
    
    await engine.run()
    
    # Assertions
    assert (tmp_path / "content").exists()
    assert len(list((tmp_path / "content").glob("*.md"))) == 10
    assert engine.pages_completed == 10
```

**Escenario 2: Recuperaci√≥n de Fallos**
```python
@pytest.mark.integration
async def test_retry_on_network_failure(mock_server):
    """Verifica que URLs fallidas se reintentan"""
    mock_server.add_failure("http://flaky.com/page1", times=2)
    
    engine = ArgeliaMigrationEngine(...)
    await engine.run()
    
    # Debe haber intentado 3 veces (1 inicial + 2 retries)
    assert mock_server.request_count("http://flaky.com/page1") == 3
```

**Escenario 3: Concurrencia Alta**
```python
@pytest.mark.slow
async def test_high_concurrency_no_corruption():
    """20 workers procesando 100 URLs simult√°neas"""
    config = ScraperConfig(default_workers=20)
    engine = ArgeliaMigrationEngine(config, ...)
    
    await engine.run()
    
    # Verificar integridad de DB (no race conditions)
    async with aiosqlite.connect(engine.state.db_path) as db:
        cursor = await db.execute("SELECT COUNT(DISTINCT url) FROM urls")
        unique_urls = (await cursor.fetchone())[0]
        
        cursor = await db.execute("SELECT COUNT(*) FROM urls")
        total_urls = (await cursor.fetchone())[0]
        
        assert unique_urls == total_urls  # No duplicados
```

---

### 6.2 Testing de Carga

**Objetivo:** Validar que el sistema aguanta casos enterprise

**Perfil de Carga:**
- 10,000 URLs √∫nicas
- 20 workers concurrentes
- Mix de contenido: 70% HTML, 20% im√°genes, 10% PDFs
- Duraci√≥n estimada: 2 horas

**M√©tricas a Monitorear:**
```python
# Script de monitoreo
import psutil
import time

def monitor_scraper(pid):
    process = psutil.Process(pid)
    
    while process.is_running():
        print(f"CPU: {process.cpu_percent()}%")
        print(f"RAM: {process.memory_info().rss / 1024**2:.2f} MB")
        print(f"Threads: {process.num_threads()}")
        print(f"Open Files: {len(process.open_files())}")
        time.sleep(30)
```

**Criterios de √âxito:**
- [ ] CPU <80% promedio
- [ ] RAM <2GB (sin memory leaks)
- [ ] Sin file descriptor leaks
- [ ] Throughput >50 p√°ginas/min

---

## 7. M√âTRICAS DE √âXITO

### 7.1 KPIs T√©cnicos

| M√©trica | Baseline (v2.2) | Target (v3.0) | Medici√≥n |
|---------|-----------------|---------------|----------|
| **Rendimiento** |
| Workers estables | 5 | 20 | Load test 1h |
| Throughput | 30 p√°g/min | 50 p√°g/min | Benchmark real |
| Latencia P95 | 8s | 5s | Prometheus |
| **Confiabilidad** |
| Tasa de fallos | 5% | <1% | Logs an√°lisis |
| Recovery autom√°tico | 60% | 95% | Retry tests |
| **Mantenibilidad** |
| Cobertura tests | 0% | 85% | pytest-cov |
| Complejidad ciclom√°tica | 45 | <15 | radon |
| L√≠neas por funci√≥n | 80 avg | <30 avg | pylint |
| **Usabilidad** |
| Tiempo setup nuevo dev | 4h | 30min | Onboarding real |
| Config manual | S√≠ | No | Wizard funcional |

### 7.2 Validaci√≥n de Negocio

**Caso de Uso Real:** Migraci√≥n sitio enterprise (50K p√°ginas)

**Checklist de Validaci√≥n:**
- [ ] Completado en <48h (vs 1 semana actual)
- [ ] 0 intervenciones manuales
- [ ] Logs analizables para reportes cliente
- [ ] Todos los assets cr√≠ticos descargados
- [ ] Markdown de calidad suficiente para RAG

---

## 8. RIESGOS Y MITIGACI√ìN

### 8.1 Riesgos T√©cnicos

#### RIESGO-1: Breaking Changes Inesperados
**Probabilidad:** Alta  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Mantener v2.2 en branch `legacy` por 6 meses
- Script de migraci√≥n autom√°tico
- Release notes detallados
- Beta testing con 3 usuarios clave antes de GA

#### RIESGO-2: Regresi√≥n de Performance
**Probabilidad:** Media  
**Impacto:** Cr√≠tico  
**Mitigaci√≥n:**
- Benchmarks obligatorios en CI/CD
- Si rendimiento cae >10%, bloquear merge
- Profiling con py-spy en cada fase

#### RIESGO-3: SQLite Pool Bugs
**Probabilidad:** Media  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Usar librer√≠as battle-tested (aiosqlite + asyncio.Queue)
- Load tests espec√≠ficos para pool
- Fallback a conexiones directas si pool falla

#### RIESGO-4: Scope Creep
**Probabilidad:** Alta  
**Impacto:** Timeline  
**Mitigaci√≥n:**
- PRD firmado por stakeholders
- Tablero Kanban con l√≠mites WIP
- Reuniones de checkpoint cada 3 d√≠as

---

### 8.2 Riesgos de Proyecto

#### RIESGO-5: Desarrollador Bloqueado
**Probabilidad:** Media  
**Impacto:** Timeline  
**Mitigaci√≥n:**
- Pair programming en componentes cr√≠ticos
- Code reviews dentro de 4h
- Documentaci√≥n inline clara

#### RIESGO-6: Testing Insuficiente
**Probabilidad:** Media  
**Impacto:** Calidad  
**Mitigaci√≥n:**
- Gate de cobertura en CI (m√≠nimo 80%)
- QA manual de casos edge antes de release
- Beta testing 1 semana antes de GA

---

## 9. TIMELINE Y RECURSOS

### 9.1 Cronograma Detallado

#### Formato de Lectura
- **[BE]** = Backend Engineer (Full-time)
- **[QA]** = QA Engineer (Part-time)
- **[TW]** = Tech Writer (Part-time)
- **‚ö†Ô∏è** = Punto de validaci√≥n obligatorio
- **üîí** = Tarea bloqueante para siguiente fase

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           SEMANA 1: FUNDACI√ìN                              ‚îÇ
‚îÇ                    Objetivo: Infraestructura sin romper v2.2               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

D√çA 1 (Lunes) - Setup Inicial
‚îú‚îÄ 09:00-10:00 [BE] Kickoff + Revisi√≥n del PRD
‚îú‚îÄ 10:00-12:00 [BE] üîí Crear estructura modular de directorios
‚îÇ                    Output: argelia_scraper/__init__.py con exports
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Mover modelos a models.py (sin cambiar l√≥gica)
‚îú‚îÄ 15:00-17:00 [BE] Setup de pytest + conftest.py base
‚îî‚îÄ 17:00-17:30 [BE] ‚ö†Ô∏è Checkpoint: Tests dummy passing en CI

D√çA 2 (Martes) - Sistema de Configuraci√≥n
‚îú‚îÄ 09:00-11:00 [BE] Implementar ScraperConfig completo
‚îÇ                    Archivo: config.py (150 l√≠neas aprox)
‚îú‚îÄ 11:00-12:00 [BE] Wizard interactivo con questionary
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Tests de config.py (10 test cases)
‚îÇ                    - test_load_from_yaml()
‚îÇ                    - test_env_override()
‚îÇ                    - test_wizard_flow()
‚îÇ                    - test_path_expansion()
‚îú‚îÄ 15:00-16:30 [QA] Review de tests + casos edge
‚îî‚îÄ 16:30-17:00 [BE] ‚ö†Ô∏è Code Review: config.py (aprobar antes de continuar)

D√çA 3 (Mi√©rcoles) - Connection Pool
‚îú‚îÄ 09:00-11:30 [BE] üîí Implementar SQLitePool
‚îÇ                    Archivo: db_pool.py (120 l√≠neas aprox)
‚îÇ                    Features:
‚îÇ                    - async context manager
‚îÇ                    - pool de 5 conexiones default
‚îÇ                    - PRAGMA optimizations
‚îú‚îÄ 11:30-12:00 [BE] Documentar API de pool (docstrings)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Tests de db_pool.py (8 test cases)
‚îÇ                    - test_acquire_release()
‚îÇ                    - test_concurrent_access()
‚îÇ                    - test_pool_exhaustion()
‚îú‚îÄ 15:00-16:00 [BE] Benchmark: Pool vs Direct connections
‚îî‚îÄ 16:00-17:00 [QA] Load test del pool (100 concurrent queries)

D√çA 4 (Jueves) - Logging Setup
‚îú‚îÄ 09:00-10:30 [BE] Configurar loguru con rotaci√≥n
‚îÇ                    - Migrar todos los print() a logger
‚îÇ                    - Setup de niveles (DEBUG, INFO, WARNING)
‚îú‚îÄ 10:30-12:00 [BE] Integrar logger en StateManager
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [BE] Tests de logging (verificar rotaci√≥n)
‚îú‚îÄ 14:30-16:00 [TW] Iniciar README.md (Secci√≥n: Getting Started)
‚îî‚îÄ 16:00-17:00 [BE] ‚ö†Ô∏è Integration test: Config + Pool + Logging

D√çA 5 (Viernes) - Consolidaci√≥n Fase 1
‚îú‚îÄ 09:00-11:00 [BE] Refactorizar StateManager para usar Pool
‚îÇ                    Cambio cr√≠tico: Reemplazar aiosqlite.connect()
‚îÇ                    con self.pool.acquire()
‚îú‚îÄ 11:00-12:00 [BE] Tests de StateManager refactorizado
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:00 [QA] Smoke tests completos de Fase 1
‚îú‚îÄ 14:00-15:30 [BE] Fix de bugs encontrados por QA
‚îú‚îÄ 15:30-16:30 [TW] Documentar cambios de Fase 1
‚îî‚îÄ 16:30-17:00      ‚ö†Ô∏è MILESTONE 1: Demo interno + Retrospectiva

ENTREGABLES SEMANA 1:
‚úÖ Estructura modular funcional
‚úÖ ScraperConfig con wizard operativo
‚úÖ SQLitePool integrado y testeado
‚úÖ Logging con rotaci√≥n activo
‚úÖ Cobertura de tests: >80% en m√≥dulos nuevos
‚úÖ Branch feat/foundation listo para merge


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SEMANA 2: SEPARACI√ìN DE RESPONSABILIDADES                 ‚îÇ
‚îÇ              Objetivo: Modularizar sin cambiar comportamiento              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

D√çA 1 (Lunes) - Utils Layer
‚îú‚îÄ 09:00-10:30 [BE] Crear utils/url_utils.py
‚îÇ                    Mover: smart_url_normalize(), slugify()
‚îú‚îÄ 10:30-12:00 [BE] Tests de url_utils.py (12 casos edge)
‚îÇ                    URLs con: tildes, espacios, %encode doble,
‚îÇ                    queries complejas, fragments
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [BE] Crear utils/text_utils.py
‚îÇ                    Wrappers de ftfy con logging
‚îú‚îÄ 14:30-16:00 [BE] Tests de text_utils.py
‚îî‚îÄ 16:00-17:00 [QA] Verificar que utils NO tienen side effects

D√çA 2 (Martes) - HTML Cleaner
‚îú‚îÄ 09:00-11:00 [BE] üîí Crear utils/html_cleaner.py
‚îÇ                    Mover: pre_clean_html(), prune_by_density()
‚îÇ                    get_text_density()
‚îú‚îÄ 11:00-12:00 [BE] Optimizar algoritmo de poda (si es posible)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:30 [BE] Tests con HTML fixtures reales (10 sitios)
‚îÇ                    - Sitio con men√∫s gigantes
‚îÇ                    - Sitio con popups
‚îÇ                    - Sitio con sidebar
‚îÇ                    - Sitio limpio (no debe romper)
‚îú‚îÄ 15:30-16:30 [QA] Review de limpieza (inspecci√≥n manual)
‚îî‚îÄ 16:30-17:00 [BE] ‚ö†Ô∏è Code Review: Utils layer completo

D√çA 3 (Mi√©rcoles) - Extractors Base
‚îú‚îÄ 09:00-10:30 [BE] Crear extractors/base.py
‚îÇ                    Interface IExtractor (abstract class)
‚îú‚îÄ 10:30-12:00 [BE] Crear extractors/text_extractor.py
‚îÇ                    Mover l√≥gica de Trafilatura + MarkItDown
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Tests de text_extractor con 5 formatos HTML
‚îÇ                    - Art√≠culo blog
‚îÇ                    - P√°gina corporativa
‚îÇ                    - Documentaci√≥n t√©cnica
‚îÇ                    - FAQ
‚îÇ                    - Landing page
‚îú‚îÄ 15:00-16:30 [BE] Crear extractors/metadata_extractor.py
‚îî‚îÄ 16:30-17:00 [BE] Tests de metadata (Open Graph, Schema.org)

D√çA 4 (Jueves) - Asset Extractor
‚îú‚îÄ 09:00-11:00 [BE] Crear extractors/asset_extractor.py
‚îÇ                    L√≥gica de descarga + conversi√≥n PDF/Office
‚îú‚îÄ 11:00-12:00 [BE] Implementar filtrado por tipo (only_images, etc)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Tests con mocks de descarga
‚îÇ                    - Imagen v√°lida
‚îÇ                    - PDF v√°lido
‚îÇ                    - Archivo corrupto
‚îÇ                    - 404 en asset
‚îú‚îÄ 15:00-16:00 [QA] Integration test: Descargar 100 assets reales
‚îî‚îÄ 16:00-17:00 [BE] ‚ö†Ô∏è Code Review: Extractors completos

D√çA 5 (Viernes) - StateManager Refactor
‚îú‚îÄ 09:00-11:30 [BE] Refactorizar StateManager para separar concerns
‚îÇ                    M√©todos privados para queries complejas
‚îÇ                    Transacciones expl√≠citas
‚îú‚îÄ 11:30-12:00 [BE] Documentar API p√∫blica de StateManager
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [BE] Tests de StateManager (15 casos)
‚îú‚îÄ 14:30-15:30 [QA] Integration tests: Extractors + StateManager
‚îú‚îÄ 15:30-16:30 [TW] Actualizar README con nueva arquitectura
‚îî‚îÄ 16:30-17:00      ‚ö†Ô∏è MILESTONE 2: Review de arquitectura modular

ENTREGABLES SEMANA 2:
‚úÖ M√≥dulo utils completo (url, text, html)
‚úÖ Extractors funcionando independientemente
‚úÖ StateManager refactorizado
‚úÖ Cobertura de tests: >85% acumulado
‚úÖ 0 dependencias circulares (verificar con pydeps)
‚úÖ Branch feat/modularization listo


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SEMANA 3: INTEGRACI√ìN Y OPTIMIZACI√ìN                      ‚îÇ
‚îÇ           Objetivo: Unir m√≥dulos y mejorar performance cr√≠tico             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

D√çA 1 (Lunes) - Engine Refactor (Parte 1)
‚îú‚îÄ 09:00-10:00 [BE] Dise√±ar dependency injection para Engine
‚îÇ                    Constructor: (config, state, extractors)
‚îú‚îÄ 10:00-12:00 [BE] üîí Refactorizar __init__ de Engine
‚îÇ                    Inyectar todas las dependencias
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Refactorizar process_page() para usar extractors
‚îÇ                    Separar: fetch ‚Üí clean ‚Üí extract ‚Üí persist
‚îú‚îÄ 15:00-16:30 [BE] Tests de process_page() con mocks
‚îî‚îÄ 16:30-17:00 [BE] Benchmark: Comparar velocidad con v2.2

D√çA 2 (Martes) - Engine Refactor (Parte 2)
‚îú‚îÄ 09:00-11:00 [BE] Refactorizar download_asset() para usar AssetExtractor
‚îú‚îÄ 11:00-12:00 [BE] Simplificar l√≥gica de workers (delegar a extractors)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Implementar DNS override configurable
‚îÇ                    Leer de config.dns_overrides
‚îÇ                    Construir browser_args din√°micamente
‚îú‚îÄ 15:00-16:30 [BE] Tests con DNS custom
‚îî‚îÄ 16:30-17:00 [QA] ‚ö†Ô∏è Smoke test: Scraping end-to-end

D√çA 3 (Mi√©rcoles) - Optimizaci√≥n de Pipeline
‚îú‚îÄ 09:00-11:00 [BE] Implementar paralelizaci√≥n de extractors
‚îÇ                    asyncio.gather([text, metadata, assets])
‚îú‚îÄ 11:00-12:00 [BE] Cache de resultados de limpieza HTML
‚îÇ                    LRU cache para evitar re-procesar
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [BE] Implementar batch inserts en StateManager
‚îÇ                    Agrupar 50 URLs antes de escribir DB
‚îú‚îÄ 14:30-16:00 [BE] Profiling con py-spy
‚îÇ                    Identificar bottlenecks reales
‚îú‚îÄ 16:00-17:00 [BE] Optimizar top 3 bottlenecks detectados

D√çA 4 (Jueves) - Scope Control y Edge Cases
‚îú‚îÄ 09:00-10:30 [BE] Mejorar l√≥gica de Scope (STRICT/BROAD/SMART)
‚îÇ                    Asegurar que respeta config correctamente
‚îú‚îÄ 10:30-12:00 [BE] Tests de scope con sitios reales
‚îÇ                    - Blog en subdirectorio
‚îÇ                    - Portal con m√∫ltiples secciones
‚îÇ                    - Sitio multi-idioma
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Implementar circuit breaker para sitios lentos
‚îÇ                    Si 5 timeouts seguidos ‚Üí pausar dominio 5min
‚îú‚îÄ 15:00-16:30 [QA] Load test con 20 workers
‚îî‚îÄ 16:30-17:00 [BE] ‚ö†Ô∏è Performance review: Throughput >50 p√°g/min

D√çA 5 (Viernes) - Consolidaci√≥n Fase 3
‚îú‚îÄ 09:00-11:00 [BE] Integration test completo (1000 URLs)
‚îú‚îÄ 11:00-12:00 [BE] Fix de bugs encontrados
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [QA] Verificar que NO hay regresi√≥n vs v2.2
‚îÇ                    Comparar output de 10 sitios reales
‚îú‚îÄ 14:30-16:00 [TW] Documentar optimizaciones y benchmarks
‚îî‚îÄ 16:00-17:00      ‚ö†Ô∏è MILESTONE 3: Demo de performance

ENTREGABLES SEMANA 3:
‚úÖ Engine refactorizado (50% menos l√≠neas)
‚úÖ Pipeline optimizado (throughput +40%)
‚úÖ DNS override configurable
‚úÖ Circuit breaker implementado
‚úÖ Benchmarks documentados
‚úÖ Branch feat/optimization listo


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SEMANA 4: TESTING Y HARDENING                           ‚îÇ
‚îÇ              Objetivo: Asegurar calidad enterprise-grade                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

D√çA 1 (Lunes) - Suite de Tests Unitarios
‚îú‚îÄ 09:00-10:00 [QA] Audit de cobertura actual (debe estar >80%)
‚îú‚îÄ 10:00-12:00 [BE] Completar tests faltantes para llegar a 85%
‚îÇ                    Foco en: error handling, edge cases
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [QA] Dise√±ar 3 escenarios de integration tests
‚îÇ                    1. Scraping end-to-end (10 p√°ginas)
‚îÇ                    2. Retry con network failures
‚îÇ                    3. High concurrency (20 workers)
‚îú‚îÄ 15:00-17:00 [BE] Implementar integration tests dise√±ados por QA

D√çA 2 (Martes) - Error Handling
‚îú‚îÄ 09:00-10:30 [BE] Crear excepciones tipadas por categor√≠a
‚îÇ                    - NetworkError
‚îÇ                    - ParsingError
‚îÇ                    - StorageError
‚îú‚îÄ 10:30-12:00 [BE] Implementar retry con backoff exponencial
‚îÇ                    1s ‚Üí 2s ‚Üí 4s ‚Üí 8s (max 3 retries)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Mejorar logging de errores (incluir context)
‚îú‚îÄ 15:00-16:30 [QA] Tests de error scenarios (15 casos)
‚îî‚îÄ 16:30-17:00 [BE] ‚ö†Ô∏è Code Review: Error handling

D√çA 3 (Mi√©rcoles) - Load Testing
‚îú‚îÄ 09:00-12:00 [QA] üîí Ejecutar load test completo
‚îÇ                    10,000 URLs | 20 workers | 2 horas
‚îÇ                    Monitorear: CPU, RAM, open files
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Analizar resultados + Fix de memory leaks
‚îú‚îÄ 15:00-16:30 [QA] Re-run load test (validar fixes)
‚îî‚îÄ 16:30-17:00      ‚ö†Ô∏è Checkpoint: ¬øPas√≥ criterios de performance?

D√çA 4 (Jueves) - Documentaci√≥n
‚îú‚îÄ 09:00-11:00 [TW] README.md completo
‚îÇ                    - Installation
‚îÇ                    - Quick Start
‚îÇ                    - Configuration
‚îÇ                    - CLI Usage
‚îÇ                    - Troubleshooting
‚îú‚îÄ 11:00-12:00 [TW] MIGRATION_GUIDE.md (v2.2 ‚Üí v3.0)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-14:30 [TW] API Reference (autogen con Sphinx)
‚îú‚îÄ 14:30-16:00 [BE] Docstrings en todos los m√≥dulos p√∫blicos
‚îú‚îÄ 16:00-17:00 [TW] CHANGELOG.md siguiendo Keep a Changelog

D√çA 5 (Viernes) - Release Candidate
‚îú‚îÄ 09:00-10:00 [BE] Tag de versi√≥n v3.0.0-rc1
‚îú‚îÄ 10:00-11:00 [BE] Build de package para PyPI (test)
‚îú‚îÄ 11:00-12:00 [QA] Instalaci√≥n desde scratch (validar wizard)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00      Beta testing con 3 usuarios clave
‚îÇ                    Recoger feedback en GitHub Issues
‚îú‚îÄ 15:00-16:30 [BE] Triage de feedback + Quick fixes
‚îî‚îÄ 16:30-17:00      ‚ö†Ô∏è MILESTONE 4: Go/No-Go para release

ENTREGABLES SEMANA 4:
‚úÖ Cobertura de tests: >85%
‚úÖ Load test passing (10K URLs sin crashes)
‚úÖ Documentaci√≥n completa
‚úÖ Release Candidate publicado
‚úÖ Feedback de beta testing procesado
‚úÖ Branch feat/testing listo


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SEMANA 5: RELEASE Y ROLLOUT (Buffer)                    ‚îÇ
‚îÇ                  Objetivo: Lanzamiento estable a producci√≥n                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

D√çA 1 (Lunes) - Fixes Post-Beta
‚îú‚îÄ 09:00-12:00 [BE] Implementar fixes de feedback cr√≠tico
‚îÇ                    (Bugs P0 y P1 del beta testing)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [QA] Regression test completo
‚îú‚îÄ 15:00-17:00 [BE] Actualizar docs con cambios finales

D√çA 2 (Martes) - Pre-Release Validation
‚îú‚îÄ 09:00-11:00 [QA] Final smoke tests en 3 entornos
‚îÇ                    - Linux (Fedora)
‚îÇ                    - macOS
‚îÇ                    - Windows (WSL)
‚îú‚îÄ 11:00-12:00 [BE] Build final de package
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [TW] Preparar release notes
‚îú‚îÄ 15:00-16:00 [BE] Tag de versi√≥n v3.0.0 (final)
‚îî‚îÄ 16:00-17:00      ‚ö†Ô∏è Final Go/No-Go meeting

D√çA 3 (Mi√©rcoles) - Release Day üöÄ
‚îú‚îÄ 09:00-10:00 [BE] Publicar en PyPI
‚îÇ                    uv pip install argelia-scraper==3.0.0
‚îú‚îÄ 10:00-11:00 [BE] Actualizar Docker image
‚îú‚îÄ 11:00-12:00      Anuncio interno (Slack, Email)
‚îú‚îÄ 12:00-13:00      ALMUERZO (Celebraci√≥n üéâ)
‚îú‚îÄ 13:00-15:00      Monitoreo activo (Sentry, logs)
‚îú‚îÄ 15:00-17:00      Soporte a early adopters

D√çA 4 (Jueves) - Post-Release Monitoring
‚îú‚îÄ 09:00-12:00      Analizar m√©tricas de uso real
‚îÇ                    - Error rate
‚îÇ                    - Performance real
‚îÇ                    - Adoption rate
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00 [BE] Hotfix de issues cr√≠ticos (si existen)
‚îú‚îÄ 15:00-17:00 [TW] Documentar issues comunes (FAQ)

D√çA 5 (Viernes) - Retrospectiva
‚îú‚îÄ 09:00-11:00      Team retrospective
‚îÇ                    - ¬øQu√© sali√≥ bien?
‚îÇ                    - ¬øQu√© mejorar?
‚îÇ                    - Lecciones aprendidas
‚îú‚îÄ 11:00-12:00      Planificar v3.1 (pr√≥ximo sprint)
‚îú‚îÄ 12:00-13:00      ALMUERZO
‚îú‚îÄ 13:00-15:00      Documentar decisiones de arquitectura (ADRs)
‚îú‚îÄ 15:00-16:00      Actualizar roadmap
‚îî‚îÄ 16:00-17:00      ‚ö†Ô∏è Cierre formal del proyecto

ENTREGABLES SEMANA 5:
‚úÖ v3.0.0 publicado en PyPI
‚úÖ Docker image actualizado
‚úÖ 0 bugs cr√≠ticos en producci√≥n
‚úÖ Documentaci√≥n post-release completa
‚úÖ Retrospectiva documentada
‚úÖ Roadmap v3.1 definido
```

---
